<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="description" content="RS-Agent: Automating Remote Sensing Tasks through Intelligent Agents">
    <meta name="keywords" content="Remote sensing image, Large language model,
 Agent, Retrieval-Augmented Generation (RAG)">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>RS-Agent: Automating Remote Sensing Tasks through Intelligent Agents</title>

    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.1/css/bulma.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="icon" href="images/logo.jpg">
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">


    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/js/all.min.js"></script>
    <script type="module" src="https://gradio.s3-us-west-2.amazonaws.com/3.27.0/gradio.js"></script>
    <script>MathJax = {tex: {inlineMath: [['$', '$'],['$$', '$$'], ['\\(', '\\)']]}}</script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
</head>


<style>
    .section {
        margin-bottom: -30px;
        /* Adjust this value as needed to reduce the space */
    }

    .expandable-card .card-text-container {
        max-height: 200px;
        overflow-y: hidden;
        position: relative;
    }

    .expandable-card.expanded .card-text-container {
        max-height: none;
    }

    .expand-btn {
        position: relative;
        display: none;
        background-color: rgba(255, 255, 255, 0.8);
        /* margin-top: -20px; */
        /* justify-content: center; */
        color: #510c75;
        border-color: transparent;
    }

    .expand-btn:hover {
        background-color: rgba(200, 200, 200, 0.8);
        text-decoration: none;
        border-color: transparent;
        color: #510c75;
    }

    .expand-btn:focus {
        outline: none;
        text-decoration: none;
    }

    .expandable-card:not(.expanded) .card-text-container:after {
        content: "";
        position: absolute;
        bottom: 0;
        left: 0;
        width: 100%;
        height: 90px;
        background: linear-gradient(rgba(255, 255, 255, 0.2), rgba(255, 255, 255, 1));
    }

    .expandable-card:not(.expanded) .expand-btn {
        margin-top: -40px;
    }

    .card-body {
        padding-bottom: 5px;
    }

    .vertical-flex-layout {
        justify-content: center;
        align-items: center;
        height: 100%;
        display: flex;
        flex-direction: column;
        gap: 5px;
    }

    .figure-img {
        max-width: 100%;
        height: auto;
    }

    .adjustable-font-size {
        font-size: calc(0.5rem + 2vw);
    }

    .chat-history {
        flex-grow: 1;
        overflow-y: auto;
        /* overflow-x: hidden; */
        padding: 5px;
        border-bottom: 1px solid #ccc;
        margin-bottom: 10px;
    }

    #gradio pre {
        background-color: transparent;
    }

    .table-con {
        overflow-x: auto;
    }

    table {
        width: 100%;
        border-collapse: collapse;
        text-align: center;
        margin: 0 auto;
        margin-top: 2rem;
    }

    table caption {
        text-align: center;
    }

    table tr,
    table td {
        border: 1px solid;
    }

    table td {
        padding: 0.5rem 3.5rem;
        vertical-align: middle;
    }

    table tr:first-child {
        background-color: #f2f2f2;
    }

    table tr:last-child {
        background-color: rgb(240, 243, 255);
    }

    .qual .title {
        margin-top: 2.5rem;
    }

    .title img {
        width: 3.5rem;
    }
    .mobile-yt{
        display: none;
    }
    .desktop-yt{
        display: block;
    }

    @media only screen and (max-width: 600px) {
        table td {
            padding: 0.5rem 0.5rem;
            /* Adjust padding for smaller screens */
        }

        img {
            width: 100%;
        }
        .hero img{
            width: 7rem;
        }
        .mobile-yt{
        display: block;
        }
        .desktop-yt{
            display: none;
        }
    }
</style>

<body>
    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <img src="images/logo.jpg" alt="RSagent_logo" width="100">
                        <h1 class="title is-1 publication-title">RS-Agent: Automating Remote Sensing Tasks through Intelligent Agents</h1>
                        <div class="is-size-5 publication-authors">
                            <!-- First Group of 3 Authors -->
                            <div class="author-group">
                                <span class="author-block">
                                    <a href="http://wenjia.ruantang.top/"
                                        style="color:#008AD7;font-weight:normal;">Wenjia Xu<sup>*</sup></a>,
                                </span>
                                <span class="author-block">
                                    <a href="https://sites.google.com/site/"
                                        style="color:#008AD7;font-weight:normal;">Zijian Yu</a>,
                                </span>
                            </div>

                            <!-- Second Group of 3 Authors -->
                            <div class="author-group">
                                <span class="author-block">
                                    <a href="https://scholar.google.com/citations?user=gAfFuhsAAAAJ&hl"
                                        style="color:#008AD7;font-weight:normal;">Yujie Li</a>,
                                </span>
                                <span class="author-block">
                                    <a href="https://sites.google.com/view/baiyangmu/home"
                                        style="color:#008AD7;font-weight:normal;">Baiyang Mu</a>,
                                </span>
                                <span class="author-block">
                                    <a href="https://people.ucas.ac.cn/~liguangzuo"
                                        style="color:#008AD7;font-weight:normal;">Guangzuo Li</a>,
                                </span>
                                <span class="author-block">
                                    <a href="https://jiuniu.ruantang.top/"
                                        style="color:#008AD7;font-weight:normal;">Jiuniu Wang</a>,
                                </span>
                                <span class="author-block">
                                    <a href="https://scholar.google.com/citations?user=85mAZVcAAAAJ&hl"
                                       style="color:#008AD7;font-weight:normal;">Mugen Peng</a>,
                                </span>
                            </div>
                        </div>
                        <div class="is-size-5 publication-authors">
                            State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications<br>
                            Aerospace Information Research Institute, Chinese Academy of Sciences<br>
                            Department of Computer Science, City University of Hong Kong<br>
                        </div>
                        <div class="is-size-6 publication-authors">
                            <span class="author-block"><sup>*</sup>The corresponding author</span>
                        </div>
                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <span class="link-block">
                                    <a href="https://arxiv.org/abs/2406.07089" target="_blank"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="ai ai-arxiv"></i>
                                        </span>
                                        <span>arXiv</span>
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a href="https://github.com/IntelliSensing/RS-Agent" target="_blank"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-github"></i>
                                        </span>
                                        <span>Code</span>
                                    </a>
                                </span>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="hero teaser">
        <div class="container is-max-desktop">
            <div class="hero-body">
		<h2 class="title is-3"><img src="images/logo.jpg" alt="unirs" width="60"
                        style="vertical-align: bottom;"> Abstract </h2>
                  <h4 class="subtitle has-text-justified">
                        An increasing number of models have achieved great performance in remote sensing tasks with the recent development of
	                Large Language Models (LLMs) and Visual Language Models (VLMs). However, these models are constrained to basic vision and
	                language instruction-tuning tasks, facing challenges in complex remote sensing applications. Additionally, these models
	                lack specialized expertise in professional domains. To address these limitations, we propose a LLM-driven remote sensing 
	                intelligent agent named RS-Agent. Firstly, RS-Agent is powered by a large language model (LLM) that acts as its "Central 
	                Controller," enabling it to understand and respond to various problems intelligently. Secondly, our RS-Agent integrates 
	                many high-performance remote sensing image processing tools, facilitating multi-tool and multi-turn conversations. 
	                Thirdly, our RS-Agent can answer professional questions by leveraging robust knowledge documents.
	                We conducted experiments using several datasets, e.g., RSSDIVCS, RSVQA, and DOTAv1. 
	                The experimental results demonstrate that our RS-Agent delivers outstanding performance in many tasks, i.e., scene classification, visual question answering, and object counting tasks.
                </h4>
            </div>
        </div>
    </section>

<!--    <div class="desktop-yt" style="text-align:center;">-->
<!--        <iframe width="1040" height="720" src="https://www.youtube.com/embed/KOKtkkKpNDk?si=0o0kqEAysSM98OYh"-->
<!--            title="YouTube video player" frameborder="0"-->
<!--            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"-->
<!--            allowfullscreen></iframe>-->
<!--    </div>-->

<!--    <div class ="mobile-yt" style="text-align: center; max-width: 100%;">-->
<!--        <div style="position: relative; overflow: hidden; padding-bottom: 56.25%;">-->
<!--            &lt;!&ndash; 16:9 aspect ratio. You can adjust the padding-bottom percentage accordingly. &ndash;&gt;-->
<!--            <iframe-->
<!--                style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;"-->
<!--                src="https://www.youtube.com/embed/KOKtkkKpNDk?si=0o0kqEAysSM98OYh"-->
<!--                title="YouTube video player" frameborder="0"-->
<!--                allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"-->
<!--                allowfullscreen-->
<!--            ></iframe>-->
<!--        </div>-->
<!--    </div>-->
    


    <section class="section" style="background-color:#efeff081">
        <div class="container is-max-desktop">
            <!-- Abstract. -->
            <div class="columns is-centered has-text-centered">
                <div class="column is-six-fifths">
                    <h2 class="title is-3">🏆 Contributions</h2>
                    <div class="content has-text-justified">
                        <ol type="1">
                            <li>RS-Agent employs an LLM to understand the user's requirements. The RS-Agent is powered by a large language model (LLM) as the central controller. 
                                These models accurately comprehend and interpret user intentions, adeptly analyzing the context and nuances of user inputs to discern the underlying needs and objectives behind queries. </li>
                            <br>
                            <li>RS-Agent can utilize multiple tools and engage in multiturn conversations. The RS-Agent can integrate many high-performance remote sensing image processing models. 
                                It can utilize a single model to address straightforward problems or sequentially invoke multiple models for continuous reasoning to tackle complex issues. Moreover,
                                the RS-Agent can facilitate multiple rounds of dialogue and maintain coherence and contextual understanding throughout the conversation. 
                                Its powerful capabilities enable users to engage in in-depth interactions, receiving more personalized and accurate responses. </li>
                            <br>
                            <li>RS-Agent is capable of answering questions in specialized fields. RAG technology is employed to broaden the Agent's knowledge database by integrating a specialized
                                knowledge repository, enabling it to address specific questions related to remote sensing.</li>
                        </ol>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Model Arch -->
    <section class="section">
        <div class="columns is-centered has-text-centered">
            <div class="column is-six-fifths">
                <h2 class="title is-3"><img src="images/logo.jpg" alt="unirs" width="60"
                        style="vertical-align: bottom;"> The schematic diagram of the RS-Agent. </h2>
            </div>
        </div>

        <div class="container is-max-desktop">

            <div class="columns is-centered has-text-centered">
                <div class="column is-six-fifths"
                    style="display: flex; align-items: flex-start; justify-content: center;">
                    <figure style="text-align: center;">
                        <img id="teaser" width="100%" src="images/TeaserFigure.png">
                    </figure>
                </div>
            </div>
            <div class="columns is-centered">
                <div class="column is-full-width">
                    <div class="content has-text-justified">
                        <p>RS-Agent employs an LLM to understand the user's requirements.</p>
                        <p>RS-Agent can utilize multiple tools and engage in multi-turn conversations.</p>
                        <p>RS-Agent is capable of answering questions in specialized fields.</p>
                        <p>
                            The RS-Agent integrates existing high-performance remote sensing tools. 
                            It can understand user intentions like a Central Controller, and solve user needs through planning, reasoning and action. 
                            It is also Capable of handling professional and technical knowledge in remote sensing.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <!-- Model Arch -->
    <!--Dataset-->
    <section id="grand-dataset" class="section">
        <div class="columns is-centered has-text-centered">
            <div class="column is-six-fifths">
                <h2 class="title is-3"><img src="images/logo.jpg" alt="unirs_logo" width="70"
                        style="vertical-align: bottom;">RS-Agent: Architecture</h2>
            </div>
        </div>
        <!--Dataset Pipeline-->
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column is-full-width">
                    <div class="content has-text-justified">
                        <p>
                            When ${M}_{c}$ receives query $Q$ and image $I$, ${M}_{c}$ will transmit the solution requirement ${r}_{s}$  to ${M}_{s}$ . 
                            ${M}_{s}$ employs the FIASS algorithm to derive solution guidance ${g}_{s}$ , which assists ${M}_{c}$  in selecting the appropriate tools $\hat{T}$ 
                            after dispatching the tool requirement ${r}_{t}$ to the tool space $T$. If ${M}_{c}$ requires additional knowledge guidance ${g}_{k}$, 
                            ${M}_{k}$ will provide it from ${D}_{k}$ according to the knowledge requirement ${k}_{s}$. 
                            ${M}_{c}$ will then invoke $\hat{T}$ and produce the final answer $A$ along with the processed image $\hat{I}$ .
                        </p>
                    </div>
                </div>
            </div>

            <div class="columns is-centered has-text-centered">
                <div class="column is-six-fifths"
                    style="display: flex; align-items: flex-start; justify-content: center;">
                    <figure style="text-align: center;">
                        <img id="teaser" width="80%" src="images/RS-Agent_framework.png">
                    </figure>
                </div>
            </div>
        </div>
        <br>
    </section>
    
    <!--Conv-->
<!-- DEMO Video Section -->
<section class="section">
    <div class="columns is-centered has-text-centered">
        <div class="column is-six-fifths">
            <h2 class="title is-3">Demo Video</h2>
        </div>
    </div>

    <div class="container is-max-desktop">
        <div class="columns is-centered">
            <div class="column is-full-width">
                <div class="content has-text-justified">
                    <p>Here is a demonstration of the RS-Agent in action.</p>
                    <p>Watch the video below to see how RS-Agent automates remote sensing tasks.</p>
                </div>
            </div>
        </div>

        <!-- Video Embed -->
        <div class="columns is-centered">
            <div class="column is-full-width">
                <figure style="text-align: center;">
                    <video width="600" controls>
                        <source src="images/DemoVideo.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </figure>
            </div>
        </div>
    </div>
</section>
    <!--Conv -->
    <style>
        #BibTeX {
            margin-bottom: -80px;
            /* Adjust the negative margin as needed */
        }

        #Acknowledgement {
            margin-top: -80px;
            /* Adjust the negative margin as needed */
        }
    </style>

    <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
            <h2 class="title">BibTeX</h2>
            <pre><code>
    @misc{xu2024rsagentautomatingremotesensing,
    title={RS-Agent: Automating Remote Sensing Tasks through Intelligent Agents}, 
    author={Wenjia Xu and Zijian Yu and Yixu Wang and Jiuniu Wang and Mugen Peng},
    year={2024},
    eprint={2406.07089},
    archivePrefix={arXiv},
    primaryClass={cs.CV},
    url={https://arxiv.org/abs/2406.07089}, 
}
  </code></pre>
        </div>
    </section>
    <section class="section" id="Acknowledgement">
        <div class="container is-max-desktop content">
            <h2 class="title">Acknowledgement</h2>
            <p>
                This website is adapted from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>,
                licensed under
                a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                    Commons Attribution-ShareAlike 4.0 International License</a>. We are thankful to LLaVA, GeoChat and
                    VILA for
                releasing their models and code as open-source contributions.
            </p>
        </div>
    </section>
	
</body>
</html>
<div style="text-align: center;">
    <a href="https://sklnst.bupt.edu.cn/en/" target="_blank">
        <img src="images/SKL_NST.png" width="200" height="200" alt="IVAL Logo">
    </a>
    <a href="https://github.com/IntelliSensing" target="_blank">
        <img src="images/IntellSensing.png" width="190" height="190" alt="Oryx Logo">
    </a>
    <a href="https://www.bupt.edu.cn/" target="_blank">
        <img src="images/BUPT_logo.png" width="200" height="200" alt="MBZUAI Logo">
    </a>
</div>

